# 1 内存管理

## 1.1 虚拟内存

虚拟内存是操作系统内存管理的一种方法，目的是让进程拥有连续可用的内存（一个连续完整的地址空间），且各个进程使用的内存地址互不影响。而实际上，它通常是被分隔成多个物理内存碎片，还有部分暂时存储在外部磁盘存储器上，在需要时进行数据交换。

具体方法是操作系统将内存抽象成虚拟地址空间，每个进程都拥有自己的虚拟地址空间，操作系统会提供一种机制，将不同进程的虚拟地址映射到物理地址上。

映射一般来两种方式，分段式和分页式：

1. 内存分段是根据程序的逻辑角度，分成栈段、堆段、数据段、代码段等，这样可以分离出不同属性的段，同时是一块连续的空间。会导致内存碎片和内存交换效率低的问题。
2. 内存分页是将虚拟地址空间和物理内存分成一段段固定大小的块，每一块称作一页，映射关系存放在页表中。内存管理单元（MMU）负责将进程访问的虚拟地址转换为内存物理地址。如果进程访问到的虚拟地址在页表中查不到，系统会产生缺页异常，进入系统内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行。

优点：

（1）虚拟内存地址空间是连续的，没有碎片。

（2）虚拟内存的最大空间就是CPU的最大寻址空间，不受内存大小的限制，能提供比内存更大的地址空间

|      | 透明性   | 地址空间维度 | 大小               | 目的                                                         |
| ---- | -------- | ------------ | ------------------ | ------------------------------------------------------------ |
| 分页 | 透明     | 一维地址空间 | 页大小不可变       | 用于虚拟内存，为了获取更大的地址空间                         |
| 分段 | 显示划分 | 二维地址空间 | 段大小可以动态改变 | 为了使程序和数据可以被划分为逻辑上独立的地址空间并且有助于共享和保护 |

## 1.2 分页系统地址映射

内存管理单元（MMU）管理着地址空间和物理内存的转换，其中的页表（Page Table）存储着页（程序地址空间）和页框（物理内存空间）的映射表。

一个虚拟地址分成两个部分：一部分存储页面号，一部分存储偏移量。

## 1.3 页面置换算法

作用是当出现缺页时，需要调入新页面而内存已满时，选择被置换出的物理页面。

（1）最佳置换算法（Optimal Replacement Algorithm）

所选择被置换出来的是最长时间内不再被访问的页面，通常可以保证最低的缺页率。理论最优算法。

（2）先进先出（First In First Out）

将最先进入的页面换出。缺点是容易将经常被访问的页面换出，导致缺页率升高。

（3）最近最久未使用（Least Recently Used）

将最近最久未使用的页面换出。维护一个记录最近访问过的页面链表，新访问的放在表头，这样表尾就是最近最久未访问的页面。

（4）最不经常使用（Least Frequently Used）

 记录访问次数。

（5）第二次机会算法（Second Chance Algorithm）

FIFO 算法可能会把经常使用的页面置换出去，为了避免这一问题，对该算法做一个简单的修改：当页面被访问 (读或写) 时设置该页面的 R 位为 1。需要替换的时候，检查最老页面的 R 位。如果 R 位是 0，那么这个页面既老又没有被使用，可以立刻置换掉；如果是 1，就将 R 位清 0，并把该页面放到链表的尾端，修改它的装入时间使它就像刚装入的一样，然后继续从链表的头部开始搜索。

（6）时钟（Clock）算法

第二次机会算法需要在链表中移动页面，降低了效率。时钟算法使用环形链表将页面连接起来，再使用一个指针指向最老的页面。

# 2 进程和线程

## 2.1 定义

进程：正在执行的**程序的实例**，是**资源分配的基本单位**，实现了操作系统的并发。

线程：是进程的**子任务**，是**独立调度的基本单位**，是操作系统可识别的最小执行和调度单位，用于保证程序的实时性，实现进程内部的并发。每个线程都独自占用一个虚拟处理器。每个线程的任务都不相同，但是共享同一地址空间。

## 2.2 区别

（1）一个线程只能属于一个进程，而一个进程可以有多个线程但最少有一个线程。线程依赖于进程而存在。

（2） 进程在执行过程中拥有独立的内存单元，而多个线程共享进程的内存。（资源分配给进程，同一进程的所有线程共享该进程的所有资源。同一进程中的多个线程共享代码段（代码和常量），数据段（全局变量和静态变量），扩展段（堆存储）。但是每个线程拥有自己的栈段，栈段又叫运行时段，用来存放所有局部变量和临时变量。） 

（3）进程是资源分配的最小单位，线程是独立调度的最小单位。

（4）在创建和撤销进程时，系统都要为之分配或回收**内存、I/O等**资源，而线程只需要保存和设置少量**寄存器和栈段**的内容，并不涉及存储器管理方面的操作，因此进程切换的开销远大于线程切换。

（5）进程之间不会相互影响，但是一个线程挂掉会导致整个进程挂掉。

为啥要引入线程？

进程可以使多个程序能并发执行，以提高**资源的利用率**和系统的**吞吐量**；但是其具有一些缺点：进程在同一时间只能干一件事，进程在执行的过程中如果阻塞，整个进程就会挂起，即使进程中有些工作不依赖于等待的资源，仍然不会执行。因此，操作系统引入了比进程粒度更小的线程，**作为并发执行的基本单位，从而减少程序在并发执行时所付出的时空开销，提高并发性。**

和进程相比，线程的优势如下：

（1） 从**资源**上来讲，线程是一种非常"节俭"的多任务操作方式。在Linux系统下，启动一个新的进程必须分配给它独立的地址空间，建立众多的数据表来维护它的代码段、堆栈段和数据段，这是一种"昂贵"的多任务工作方式。 

（2） 从切换效率上来讲，运行于一个进程中的多个线程，它们之间使用相同的地址空间，而且线程间彼此切换所需时间也远远小于进程间切换所需要的时间。据统计，一个进程的开销大约是一个线程开销的30倍左右。 

（3） 从**通信机制**上来讲，线程间方便的通信机制。对不同进程来说，它们具有独立的数据空间，要进行数据的传递只能通过进程间通信的方式进行，这种方式不仅费时，而且很不方便。线程则不然，由于同一进程下的线程之间共享数据空间，所以一个线程的数据可以直接为其他线程所用，这不仅快捷，而且方便。 

# 3 进程

## 3.1 状态

ready：就绪状态

running：运行状态

waiting：等待资源

（1）ready和running状态可以互相转换，其中ready->running这一过程是通过**进程间的调度算法**实现的；running->ready是进程**消耗完分配的CPU时间片**自动转换的。

（2）waiting状态是running状态缺少必要的资源转换过来的，但是该资源不包括CPU时间片，缺少时间片会转换为ready状态。

## 3.2 进程调度算法

根据如何处理时钟中断，调度算法一般分为两类：

1. 非抢占式算法：系统挑选一个进程，然后让该进程运行直到被阻塞，或者直到该进程退出，才会调用另外一个进程；
2. 抢占式算法：挑选一个进程，然后让该进程只运行某段时间，如果在该时段结束时，该进程任然在运行时，则会把它挂起，接着调度程序从就绪队列挑选另外一个进程。

调度算法：

1. **先来先服务（First Come First Served）：**非抢占式的调度算法，按照请求的先后顺序；
2. **最短作业优先（Shortest Job First）：**非抢占式算法，按照估计运行时间最短优先的原则调度；SJF还可以是抢占式的，也就是**最短剩余时间优先（Shortest Remaining Time Next）**按照最短剩余时间原则进行调度，如果新任务的时间更短，则当前进程挂起，运行新的进程。
3. **优先级调度：**为每个进程分配一个优先级，按优先级进行调度。同时为了防止低优先级的进程永远等不到调度，可以随着时间的推移增加等待进程的优先级。
4. **时间片轮转：**将所有就绪进程按 FCFS 的原则排成一个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。 缺点：时间片太小，进程频繁切换降低效率；时间片太大，实时性无法保证。
5. **多级队列：**时间片轮转调度算法和优先级调度算法的结合。 设置多个队列，每个队列的时间片长度不一样，优先级也不一样，进程在第一个队列中没执行完会被移到下一个队列中，以此减少交换次数。
6. **多级反馈队列：**基于多级队列，多级反馈队列允许进程在队列之间进程迁移。

## 3.3 进程同步

临界区：访问临界资源的代码。

同步：多个进程由于**合作产生制约关系**，使得进程的执行有一定的先后顺序。

互斥：多个进程同一时刻只能有一个进程进入临界区。

## 3.4 进程间通信

进程间通信方式主要包括管道（PIPE）、系统IPC（消息队列、信号量、信号、共享内存等）、以及套接字socket

**管道：**进程将写入的数据缓存在内核中，另一个进程读取数据时也是从内核中获取，且通信数据遵循先进先出的原则。

1. 命名管道(FIFO)：半双工通信方式，提前创建了一个类型为管道（mkfifo）的文件，允许无亲缘关系进程间的通信。优点：可以实现任意关系进程间的通信。缺点：长期存在于系统之中，使用不当容易出错；缓冲区有限。
2. 匿名管道：半双工通信方式，只允许有亲缘关系的进程间使用。优点：简单方便。缺点：局限于单向通信，只能创建在它的进程以及有亲缘关系的进程间使用；缓冲区有限。

**消息队列：**是保存在内核中的消息链表，在发送数据时，会分成一个个独立的消息体（数据块，用户自定义数据类型）。消息队列生命周期在没有释放时会一直存在。

- 优点：可以实现任意进程之间的通信，并通过系统调用函数来实现消息发送和接收之间的同步，无需考虑同步问题，方便。
- 缺点：通信过程存在用户态与内核态之间的数据拷贝开销。

**共享内存：**拿出一块虚拟地址空间，映射到相同的物理内存中，这段共享内存由一个进程创建，但多个进程都可以访问。

- 优点：无需复制，快捷，信息量大。
- 缺点：通信是通过将共享空间缓冲区直接附加到进程的虚拟地址空间中来实现的，因此会带来进程间读写操作的同步问题；利用内存缓冲区之间交换信息，内存的实体存在于计算机中，只能同一个计算机词统中的诸多进程共享，不方便网络通信。

**信号量：**一个计数器，主要用于实现进程间的互斥和同步，可以用来控制多个线程对**共享资源**的访问。

- 优点：可以同步进程。
- 缺点：信号量有限

**信号：**进程间的一种异步通信机制，可以在任何时候发送信号给某一进程。				

**套接字：**可用不同计算机之间的进程通信。

# 4 线程

线程间的通信目的主要是用于**线程同步**，所以线程没有像进程通信中的用于数据交换的通信机制。

## 4.1 互斥与同步

条件竞争：当多线程相互竞争操作共享变量时，由于运气不好，在执行过程中发生了上下文切换，导致错误的结果。在这种情况下，每次运行都会得到不同的结果，输出的结果存在不确定性。

互斥：一个线程在临界区执行时，其它线程应该被阻止进入临界区。

同步：并发线程/进程在一些关键点上可能需要互相等待与互通消息，这种相互制约的等待与互通消息称为进程/线程同步。

## 4.2 实现

锁机制

1. 互斥锁（mutex）：提供了以排他方式防止数据结构被并发修改的方法。
2. 读写锁（Read-Write Lock）：允许多个线程同时共享数据，而对写操作是互斥的。
3. 自旋锁（spin lock）：与互斥锁类似，都是为了保护共享资源。互斥锁是当前资源被占用，申请者进入休眠状态；而自旋锁则循环检测保持者是否已经释放锁。
4. 条件变量（condition）：可以以原子的方式阻塞进程，直到某个条件为真为止。对条件的测试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用。

信号量机制

信号机制

屏蔽：屏障允许每个线程等待，直到所有的合作线程都达到某一点，然后从该点继续执行。 

## 4.3 协程

协程，可被认为是在应用层模拟的线程，类似于函数，避免了线程切换带来的额外损耗，同时具有并发运行的优点。

一般来说，协程的内部实现还是基于线程，思路是维护一组数据结构和多个线程，真正的执行者还是线程，协程执行的代码被放到待执行队列中，由线程执行，类似于线程池和任务队列。

# 5 死锁

## 5.1 含义

死锁是指两个或两个以上的进程在执行过程中，由于**竞争资源或者由于彼此通信而造成的一种互相等待**的现象，若无外力作用，它们都将无法推进下去。此时称系统产生了死锁或系统处于死锁状态，这些永远在互相等待的进程称为死锁进程。 

产生原因：系统资源不足、资源分配不当、进程运行推进顺序不合适

## 5.2 必要条件

（1）互斥：多个线程不同同时使用一个资源。

（2）占有和等待：已经得到了某个资源的进程可以再请求新的资源，但在申请资源的过程中不会释放原有资源。

（3）不可抢占：已经分配给一个进程的资源不能强制性地被抢占，它只能被占有它的进程显式地释放。

（4）环路等待：有两个或者两个以上的进程组成一条环路，该环路中的每个进程都在等待下一个进程所占有的资源。

## 5.3 处理方法

（1）鸵鸟策略：不理会死锁，直接忽略。

（2）死锁检测与死锁恢复：不试图阻止死锁，而是检测到死锁发生时，采取措施进行恢复。

​		死锁恢复：利用抢占恢复，利用回滚恢复，通过杀死进程恢复。

（3）死锁预防：在程序运行之前预防发生死锁。

- 破环互斥条件

- 破坏和占有等待条件

- 破坏不可抢占条件

- 破坏环路等待


（4）死锁避免：在程序运行时避免发生死锁。

安全状态：如果没有死锁发生，并且即使所有进程突然请求对资源的最大需求，也任然存在某种调度次序能够使得每一个进程运行完毕，则称该状态是安全的。（银行家算法）

a.避免嵌套锁：

 一个线程已获得一个锁时，再别去获取第二个。因为每个线程只持有一个锁，锁上就不会产生死锁。即使互斥锁造成死锁的最常见原因，也可能会在其他方面受到死锁的困扰(比如：线程间的互相等待)。当你需要获取多个锁，使用一个`std::lock`来做这件事(对获取锁的操作上锁)，避免产生死锁。 

b.避免在持有锁时调用用户提供的代码：

 因为代码是用户提供的，你没有办法确定用户要做什么；用户程序可能做任何事情，包括获取锁。你在持有锁的情况下，调用用户提供的代码；如果用户代码要获取一个锁，就会违反第一个指导意见，并造成死锁(有时，这是无法避免的)。 

c.使用固定顺序获取锁

 当硬性条件要求你获取两个或两个以上的锁，并且不能使用`std::lock`单独操作来获取它们；那么最好在每个线程上，用固定的顺序获取它们(锁)。3.2.4节中提到，当需要获取两个互斥量时，避免死锁的方法，关键是如何在线程之间，以一定的顺序获取锁。 

d.使用锁的层次结构

 虽然，定义锁的顺序是一种特殊情况，但锁的层次的意义在于提供对运行时约定是否被坚持的检查。这个建议需要对你的应用进行分层，并且识别在给定层上所有可上锁的互斥量。当代码试图对一个互斥量上锁，在该层锁已被低层持有时，上锁是不允许的。你可以在运行时对其进行检查，通过分配层数到每个互斥量上，以及记录被每个线程上锁的互斥量。 

## 5.4 锁的分类

（1）互斥锁和自旋锁

当已有的一个线程加锁后，其它线程就会加锁失败，互斥锁和自旋锁对于加锁失败后的处理方式不一样：

- 互斥锁：加锁失败后，线程会**释放CPU**给其线程，表现为**阻塞**。
- 自旋锁：加锁失败后，线程会**忙等待**，直到拿到锁。

（2）读写锁

（2）乐观锁和悲观锁

- 乐观锁：假定不会出现竞争，先修改资源，再验证这段时间内有没有发生冲突，如果没有其它线程在修改资源，那么操作完成；如果有其它线程修改过资源，就放弃本次操作。例如在线文档。
- 悲观锁：修改资源前必定上锁。

# 6 IO系统

## 6.1 零拷贝

标准的 Linux 系统 I/O 接口（read、write）默认都是缓冲 I/O，当应用程序访问某块数据时，操作系统首先会检查，是不是最近访问过此文件，文件内容是否缓存在内核缓冲区，如果是，操作系统则直接根据`read`系统调用提供的`buf`地址，将内核缓冲区的内容拷贝到`buf`所指定的用户空间缓冲区中去。如果不是，操作系统则首先将磁盘上的数据拷贝的内核缓冲区，这一步目前主要依靠`DMA`来传输，然后再把内核缓冲区上的内容拷贝到用户缓冲区中。

<img src="D:\Desktop\PlanBrick\CPP\interview\pics\zerocopy.jpg" style="zoom:50%;" />

实现方式：

（1）mmap + write

mmap 是 Linux 提供的一种内存映射文件的机制，它实现了将内核中读缓冲区地址与用户空间缓冲区地址进行映射，从而实现内核缓冲区与用户缓冲区的共享。

read（该调用可以是用来读文件的） 系统调用会把内核缓冲区的数据拷贝到用户缓冲区中，通过使用 mmap 替换 read 可以省掉这一过程。mmap 会把内核缓冲区里的数据“映射”到用户空间，这样就减少了一次用户态和内核态的CPU拷贝。

<img src="D:\Desktop\PlanBrick\CPP\interview\pics\mmap.PNG" style="zoom:50%;" />

（2）sendfile

专门用来发送文件的函数，可以直接把内核缓冲区里的函数直接拷贝到 socket 缓冲区里，不用再拷贝到用户态，减少了两次上下文切换的开销。

<img src="D:\Desktop\PlanBrick\CPP\interview\pics\sendfile.PNG" style="zoom:50%;" />

（3）splice

splice系统调用是Linux 在 2.6 版本引入的，其不需要硬件支持，并且不再限定于socket上，实现两个普通文件之间的数据零拷贝。

## 6.2 IO 模型

**文件描述符**（File Descriptor，**fd**）：用于表示指向文件的引用的抽象化概念。

文件描述符在形式上是一个非负整数。实际上，它是一个索引值，指向内核为每一个进程所维护的**该进程打开文件的记录表**。当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。在程序设计中，一些涉及底层的程序编写往往会围绕着文件描述符展开。但是文件描述符这一概念往往只适用于UNIX、Linux这样的操作系统。

**缓存I/O**：又称标准I/O，在 Linux 的缓存 I/O 机制中，操作系统会将 I/O 的数据缓存在文件系统的页缓存（ page cache ）中，也就是说，数据会**先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。**

**I/O模式**：对于一次I/O访问（以read举例），数据会先被拷贝到操作系统内核的缓冲区中，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。

所以说，当一个read操作发生时，它会经历两个阶段：

- 等待数据准备 (Waiting for the data to be ready)
- 将数据从内核拷贝到进程中 (Copying the data from the kernel to the process)

### 6.1 阻塞I/O

阻塞I/O（blocking I/O），在Linux中，默认情况下所有的socket都是blocking。

当用户进程调用了recvfrom这个系统调用，kernel就开始了IO的第一个阶段：准备数据（对于网络IO来说，很多时候数据在一开始还没有到达。比如，还没有收到一个完整的UDP包。这个时候kernel就要等待足够的数据到来）。这个过程需要等待，也就是说数据被拷贝到操作系统内核的缓冲区中是需要一个过程的。而在用户进程这边，整个进程会被阻塞（当然，是进程自己选择的阻塞）。当kernel一直等到数据准备好了，它就会将数据从kernel中拷贝到用户内存，然后kernel返回结果，用户进程才解除block的状态，重新运行起来。

所以，blocking I/O的特点就是在IO执行的两个阶段都被block了。

### 6.2 非阻塞I/O

非阻塞I/O（noblocking I/O），可以通过设置socket使其变为non-blocking。

当用户进程发出recvfrom操作时，如果kernel中的数据还没有准备好，那么它并不会block用户进程，而是立刻返回一个error。从用户进程角度讲 ，它发起一个read操作后，并不需要等待，而是马上就得到了一个结果。用户进程判断结果是一个error时，它就知道数据还没有准备好，于是它可以再次发送read操作。一旦kernel中的数据准备好了，并且又再次收到了用户进程的system call，那么它马上就将数据拷贝到了用户内存，然后返回。

所以，nonblocking IO的特点是用户进程需要**不断的主动询问**kernel数据好了没有。

### 6.3 I/O多路复用

[I/O多路复用](I/O多路复用)（I/O multiplexing），也称事件驱动（event driven IO），比如poll，select，epoll。select/epoll的好处就在于单个process就可以同时处理多个网络连接的IO。它的基本原理就是select，poll，epoll这个function会不断的轮询所负责的所有socket，当某个socket有数据到达了，就通知用户进程。

（进程通过将一个或多个fd传递给select，阻塞在select操作上，select帮我们侦测多个fd是否准备就绪，当有fd准备就绪时，select返回数据可读状态，应用程序再调用recvfrom读取数据。）

以下参考资料：https://zhuanlan.zhihu.com/p/126278747

#### 6.3.1 select

```c++
#include <sys/time.h>
#include <sys/types.h>
#include <unistd.h>
int select(int nfds, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout);

	nfds: 		监控的文件描述符集里最大文件描述符加1，因为此参数会告诉内核检测前多少个文件描述符的状态
	readfds：	监控有读数据到达文件描述符集合，传入传出参数，数组
	writefds：	监控写数据到达文件描述符集合，传入传出参数
	exceptfds：	监控异常发生达文件描述符集合,如带外数据到达异常，传入传出参数
	timeout：	定时阻塞监控时间，3种情况
				1.NULL，永远等下去
				2.设置timeval，等待固定时间
				3.设置timeval里时间均为0，检查描述字后立即返回，轮询
	struct timeval {
		long tv_sec; /* seconds */
		long tv_usec; /* microseconds */
	};
	void FD_CLR(int fd, fd_set *set); 	//把文件描述符集合里fd清除
	int FD_ISSET(int fd, fd_set *set); 	//测试文件描述符集合里fd是否置1
	void FD_SET(int fd, fd_set *set); 	//把文件描述符集合里fd位置1
	void FD_ZERO(fd_set *set); 			//把文件描述符集合里所有位清0

```

流程：

1. 在调用select之前告诉select 应用进程需要监控哪些fd可读、可写、异常事件，这些分别都存在一个fd_set数组中。
2. 然后应用进程调用select的时候把3个fd_set传给**内核**（这里也就产生了一次fd_set在用户空间到内核空间的复制，内核空间在复制的时候会做安全检查，所以比直接读数据安全），内核收到fd_set后对fd_set进行遍历，然后一个个去扫描对应fd是否满足可读写事件。
3. 如果发现了有对应的fd有读写事件后，**内核会把fd_set里没有事件状态的fd句柄清除**（所以后面需要用FD_ISSET()来判断是否有事件到达），然后把有事件的fd返回给应用进程（这里又会把fd_set从内核空间复制用户空间）。
4. 最后应用进程收到了select返回的活跃事件类型的fd句柄后，再向对应的fd发起数据读取或者写入数据操作。

select目前几乎在所有的平台上支持，其良好跨平台支持也是它的一个优点。select的一个缺点在于**单个进程能够监视的文件描述符的数量存在最大限制**，在Linux上一般为1024，可以通**过修改宏定义甚至重新编译内核**的方式提升这一限制，但是这样也会造成效率的降低。

缺点：

- 每次调用select都需要将进程加入到所有监视socket的等待队列，每次唤醒都需要从每个队列中移除。这里涉及了两次遍历，而且每次都要将整个fds列表传递给内核，有一定的开销。正是因为遍历操作开销大，出于效率的考量，才会规定select的最大监视数量，默认只能监视1024个socket。
- 进程被唤醒后，程序并不知道哪些socket收到数据，还需要遍历一次。

#### 6.3.2 poll

吸取了select的教训，poll模式就不再使用数组的方式来保存自己所监控的fd信息了，poll模型里面通过使用**链表**的形式来保存自己监控的fd信息，正是这样poll模型里面是没有了连接限制，可以支持高并发的请求。

**不同与select使用三个数组来表示三个fdset的方式，poll传入一个结构体数组pollfd，并且通过该结构体传出结果**

```c++
#include <poll.h>
int poll(struct pollfd *fds, nfds_t nfds, int timeout);
	struct pollfd {
		int fd; /* 文件描述符 */
		short events; /* 监控的事件 */
		short revents; /* 监控事件中满足条件返回的事件 */
	};
	POLLIN			普通或带外优先数据可读,即POLLRDNORM | POLLRDBAND
	POLLRDNORM		数据可读
	POLLRDBAND		优先级带数据可读
	POLLPRI 		高优先级可读数据
	POLLOUT		普通或带外数据可写
	POLLWRNORM		数据可写
	POLLWRBAND		优先级带数据可写
	POLLERR 		发生错误
	POLLHUP 		发生挂起
	POLLNVAL 		描述字不是一个打开的文件

	nfds 			监控数组中有多少文件描述符需要被监控

	timeout 		毫秒级等待
		-1：阻塞等，#define INFTIM -1 				Linux中没有定义此宏
		0：立即返回，不阻塞进程
		>0：等待指定毫秒数，如当前系统时间精度不够毫秒，向上取值

```

**pollfd结构包含了要监视的event和发生的event，不再使用select“参数-值”传递的方式**。同时，pollfd并没有最大数量限制（但是数量过大后性能也是会下降）。 和select函数一样，poll返回后，需要轮询pollfd来获取就绪的描述符。

从上面看，select和poll都需要在返回后，**通过遍历文件描述符来获取已经就绪的socket**。事实上，同时连接的大量客户端在一时刻可能只有很少的处于就绪状态，因此随着监视的描述符数量的增长，其效率也会线性下降。

#### 6.3.3 epoll

epoll是在2.6内核中提出的，是之前的select和poll的增强版本。相对于select和poll来说，epoll更加灵活，**没有描述符限制**。epoll使用一个文件描述符管理多个描述符，将用户关心的**文件描述符的事件存放到内核的一个事件表中**，这样在用户空间和内核空间的copy只需一次。

我们在调用epoll_create时，内核除了帮我们在epoll文件系统里建了个file结点，在内核cache里建了个红黑树用于存储以后epoll_ctl传来的socket外，还会再建立一个[rdllist](https://zhuanlan.zhihu.com/p/165287735)双向链表，用于存储准备就绪的事件，当epoll_wait调用时，仅仅观察这个rdllist双向链表里有没有数据即可。有数据就返回，没有数据就sleep，等到timeout时间到后即使链表没数据也返回。所以，epoll_wait非常高效。

  所有添加到epoll中的事件都会与设备(如网卡)驱动程序建立回调关系，也就是说相应事件的发生时会调用这里的回调方法。这个回调方法在内核中叫做ep_poll_callback，它会把这样的事件放到上面的rdllist双向链表中。

epoll操作过程需要三个接口，分别如下：

```c++
int epoll_create(int size)；// 创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大
int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event)；// 向epoll对象添加连接的套接字
int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout); // 收集发生事件的连接
```

（1）**int epoll_create(int size);**

创建一个epoll的句柄，size用来告诉内核这个监听的数目一共有多大，这个参数不同于select()中的第一个参数，给出最大监听的fd+1的值，**参数size并不是限制了epoll所能监听的描述符最大个数，只是对内核初始分配内部数据结构的一个建议**。内部采用红黑树实现的。

当创建好epoll句柄后，它就会占用一个fd值，在linux下如果查看/proc/进程id/fd/，是能够看到这个fd的，所以在使用完epoll后，必须调用close()关闭，否则可能导致fd被耗尽。

（2）**int epoll_ctl(int epfd, int op, int fd, struct epoll_event \*event)；**

- 函数是对指定描述符fd执行op操作。
  \- **epfd**：是epoll_create()的返回值。
  \- **op**：表示op操作，用三个宏来表示：添加EPOLL_CTL_ADD，删除EPOLL_CTL_DEL，修改EPOLL_CTL_MOD。分别添加、删除和修改对fd的监听事件。
  \- **fd**：是需要监听的fd（文件描述符）
  \- **epoll_event**：是告诉内核需要监听什么事，是一个**地址**。

struct epoll_event结构如下：

```c++
struct epoll_event {
  __uint32_t events;  /* Epoll events */
  epoll_data_t data;  /* User data variable */
};

//events可以是以下几个宏的集合：
EPOLLIN ：表示对应的文件描述符可以读（包括对端SOCKET正常关闭）；
EPOLLOUT：表示对应的文件描述符可以写；
EPOLLPRI：表示对应的文件描述符有紧急的数据可读（这里应该表示有带外数据到来）；
EPOLLERR：表示对应的文件描述符发生错误；
EPOLLHUP：表示对应的文件描述符被挂断；
EPOLLET： 将EPOLL设为边缘触发(Edge Triggered)模式，这是相对于水平触发(Level Triggered)来说的。
EPOLLONESHOT：只监听一次事件，当监听完这次事件之后，如果还需要继续监听这个socket的话，需要再次把这个socket加入到EPOLL队列里

```

（3） **int epoll_wait(int epfd, struct epoll_event \* events, int maxevents, int timeout);**

第二个参数是一个数组，是一个传入传出参数，和ctl函数里的参数不是同一个。

等待epfd上的io事件，最多返回maxevents个事件，这个过程是通过回调函数实现的。

参数events用来从内核得到事件的集合，maxevents告之内核这个events有多大，这个maxevents的值不能大于创建epoll_create()时的size，参数timeout是超时时间（毫秒，0会立即返回，-1将不确定，也有说法说是永久阻塞）。该函数返回需要处理的事件数目，如返回0表示已超时。

### 6.4 信号驱动IO

### 6.5 异步IO

用户进程发起read(recvfrom)操作之后，立刻就可以开始去做其它的事。而另一方面，从kernel的角度，当它受到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。然后，kernel会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都完成之后，kernel会给用户进程发送一个signal，告诉它read操作完成了。

# 面经总结

## 1 Linux指令

ps：查看系统进程

ps -ef：查看所有进程

kill -9：强制关掉进程

kill -15：系统通知进程让其主动关闭进程

ulimit -a ：查看打开文件配置

## 2 用户态和内核态

内核从本质上看是一种软件——控制计算机的硬件资源，并提供上层应用程序运行的环境。用户态即上层应用程序的活动空间，应用程序的执行必须依托于内核提供的资源，包括CPU资源、存储资源、I/O资源等。为了使上层应用能够访问到这些资源，内核必须为上层应用提供访问的接口：即系统调用。

用户态的应用程序可以通过三种方式来访问内核态的资源：

- 系统调用
- 库函数
- shell脚本

用户态到内核态的切换：

- 系统调用
- 外设中断
- 异常

